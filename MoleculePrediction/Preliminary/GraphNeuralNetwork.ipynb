{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import molecule_predictionv3_0 as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading molecule structures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Reading molecule structures\nReading molecule prop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Reading molecule prop\nReading Coulomb_mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done reading coulomb mat\nReading distance_mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done reading distance mat\n"
     ]
    }
   ],
   "source": [
    "dat = mp.molecule_prediction_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\ntf.py_func is deprecated in TF V2. Instead, use\n    tf.py_function, which takes a python function which manipulates tf eager\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\n    means `tf.py_function`s can use accelerators such as GPUs as well as\n    being differentiable using a gradient tape.\n    \n"
     ]
    }
   ],
   "source": [
    "atom_vector_size = mp.atom_vector_size\n",
    "num_atoms = mp.num_atoms\n",
    "num_timesteps = 5\n",
    "hidden_unit_size = atom_vector_size\n",
    "batch_size = 64\n",
    "num_epochs = 1000\n",
    "batch_gen = dat.batch_gen\n",
    "test_gen = dat.test_gen\n",
    "dataset = tf.data.Dataset.\\\n",
    "    from_generator(batch_gen.generate, (tf.float32,tf.float32, tf.float32),\n",
    "                   output_shapes= (tf.TensorShape([num_atoms,atom_vector_size]),\n",
    "                                   tf.TensorShape([num_atoms,num_atoms]),\n",
    "                                   tf.TensorShape([mp.prediction_vector_size])))                                                     \n",
    "dataset = dataset.shuffle(buffer_size = batch_size*10) \n",
    "dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "dataset = dataset.prefetch(buffer_size = 2)\n",
    "\n",
    "testset = tf.data.Dataset.\\\n",
    "    from_generator(batch_gen.generate, (tf.float32,tf.float32, tf.float32),\n",
    "                   output_shapes= (tf.TensorShape([num_atoms,atom_vector_size]),\n",
    "                                   tf.TensorShape([num_atoms,num_atoms]),\n",
    "                                   tf.TensorShape([mp.prediction_vector_size])))                                                      \n",
    "testset = testset.repeat(num_epochs).batch(batch_size)\n",
    "testset = testset.prefetch(buffer_size = 2)\n",
    "\n",
    "\n",
    "data_source =  dataset.make_one_shot_iterator()\n",
    "test_source =  testset.make_one_shot_iterator()\n",
    "\n",
    "prob = tf.placeholder_with_default(1.0, shape=())\n",
    "handle = tf.placeholder(tf.string,name=\"handle_placeholder\", shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    handle, data_source.output_types)\n",
    "\n",
    "atoms_vector_batch, ad_matrix , batch_y = iterator.get_next()\n",
    "batchSize = tf.shape(atoms_vector_batch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('message_transform_network'):\n",
    "    hidden1 = tf.keras.layers.Dense(1024,activation='tanh')\n",
    "    hidden1.build((None,atom_vector_size))\n",
    "    hidden2 = tf.keras.layers.Dense(1024,activation='tanh')\n",
    "    hidden2.build((None,1024))\n",
    "    out_message = tf.keras.layers.Dense(atom_vector_size)\n",
    "    out_message.build((None, 1024))\n",
    "def apply_edge_neural_network_transform_to_batch(batch_input):\n",
    "    input = tf.reshape(batch_input, [-1, atom_vector_size])\n",
    "    out = apply_edge_neural_network_transform(input)\n",
    "    return tf.reshape(out, [batchSize, num_atoms, atom_vector_size])    \n",
    "def apply_edge_neural_network_transform(input):\n",
    "    global prob\n",
    "    return out_message.apply(\n",
    "        hidden2.apply(\n",
    "            tf.nn.dropout(hidden1.apply(input),keep_prob=prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages_batch(ordered_atoms_vector_batch, adjancency_matrix_batch):\n",
    "    tranformed_batch = apply_edge_neural_network_transform_to_batch(\n",
    "        ordered_atoms_vector_batch)\n",
    "    return tf.matmul(adjancency_matrix_batch,tranformed_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"RecusiveUnitLTSM\"):\n",
    "    shared_lstm_cell =  tf.keras.layers.GRUCell(hidden_unit_size);\n",
    "def iterate_time_step(states_vectors_t, messages):\n",
    "    (outputs_t, states_vectors_t_1) = \\\n",
    "        shared_lstm_cell(messages, states_vectors_t)\n",
    "    return outputs_t, states_vectors_t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_state1 = tf.Variable(np.zeros(shape=(1,hidden_unit_size)),\n",
    "                            trainable=False,dtype=tf.float32);\n",
    "initial_state2 = tf.Variable(np.zeros(shape=(1,hidden_unit_size)),\n",
    "                            trainable=False,dtype=tf.float32);\n",
    "initial_states1 = tf.reshape(tf.tile(initial_state1, (1,num_atoms*batchSize)),\n",
    "                            [num_atoms*batchSize, hidden_unit_size])\n",
    "initial_states2 = tf.reshape(tf.tile(initial_state2, (1,num_atoms*batchSize)),\n",
    "                            [num_atoms*batchSize, hidden_unit_size])\n",
    "initial_states = [initial_states1,initial_states2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_neural_network_batch(atoms_vector_batch, ad_matrix):\n",
    "    global initial_states   \n",
    "    outputs_x = atoms_vector_batch\n",
    "    states_vectors_x = initial_states\n",
    "    for i in range(num_timesteps):\n",
    "        messages = get_messages_batch(outputs_x, ad_matrix)\n",
    "        messages = tf.reshape(messages, [-1, atom_vector_size])\n",
    "        outputs_x, states_vectors_x = iterate_time_step(states_vectors_x,messages)    \n",
    "        outputs_x = tf.reshape(outputs_x,[batchSize,num_atoms,atom_vector_size])\n",
    "    final_outputs = tf.reshape(outputs_x,[batchSize,num_atoms,atom_vector_size])\n",
    "    out = tf.reduce_sum(final_outputs,axis=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-ebef35dae723>:16: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "final_outputs=graph_neural_network_batch(atoms_vector_batch, ad_matrix)\n",
    "post_gnn_hidden = tf.keras.layers.Dense(512)(final_outputs)\n",
    "prediction = tf.keras.layers.Dense(mp.prediction_vector_size)(\n",
    "    tf.nn.dropout(final_outputs,keep_prob=prob))\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.losses.mean_squared_error(batch_y, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.0001\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    starter_learning_rate, global_step, 200000, 0.96, staircase=True)\n",
    "with tf.name_scope(\"train\"):\n",
    "    global training_op\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Kaggle\\Molecule\\MoleculePrediction\\molecule_predictionv3_0.py:174: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  result[insertHere] = array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 0Train Loss 12.058476\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    train_iterator_handle = sess.run(data_source.string_handle())\n",
    "    test_iterator_handle = sess.run(test_source.string_handle())\n",
    "    for epoch in range(num_epochs):\n",
    "        for iteration in range(batch_gen.samples// batch_size):\n",
    "            _,loss_value = sess.run([training_op,loss],\n",
    "                                    feed_dict=\n",
    "                                    {handle: train_iterator_handle,\n",
    "                                     prob: 0.7})  \n",
    "            if iteration % 200 == 0:\n",
    "                print(\"Epoch \" + str(epoch) + \" Step \" + str(iteration) \n",
    "                      + \"Train Loss \" + str(loss_value))\n",
    "        val_accuracy = 0\n",
    "        val_step = 1\n",
    "        for iteration in range(test_gen.samples// batch_size):\n",
    "            [loss_value] = sess.run([loss],feed_dict={handle: test_iterator_handle})        \n",
    "            val_accuracy = val_accuracy + loss_value\n",
    "            val_step = val_step + 1\n",
    "        val_accuracy = val_accuracy/val_step\n",
    "        print(\"Epoch \" + str(epoch) + \"Validation Loss \" + str(val_accuracy))\n",
    "        if epoch % 50 == 0:\n",
    "            save_path = saver.save(sess, \"../models/graph_model\" + str(epoch) + \".ckpt\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
